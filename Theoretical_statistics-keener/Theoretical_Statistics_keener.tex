\documentclass[11pt]{book}

\usepackage{fancyhdr}
\usepackage{extramarks}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{tikz}
\usepackage[plain]{algorithm}
\usepackage{algpseudocode}

\usetikzlibrary{automata,positioning}

%%%%%%%%%%%%%%%%%%%%%%%%
%%% Useful packages and commands
%%%%%%%%%%%%%%%%%%%%%%%%
% packages
\usepackage{amsmath,amssymb,amsthm}
%\usepackage{times}
%\usepackage{setspace}
\usepackage{indentfirst}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{latexsym}
\usepackage{amscd}
\usepackage{multirow}
\usepackage{array}
\usepackage{caption}
\usepackage{rotating}
\usepackage{subfig}
\usepackage{color}
\usepackage{natbib}
\usepackage{lscape}
\usepackage{graphics}
\usepackage{enumerate}
%\usepackage{fancyvrb}
%\usepackage{mathtools}
\usepackage{verbatim}
\usepackage{afterpage}
%\usepackage[ruled,vlined]{algorithm2e}
\usepackage{hyperref}
\usepackage[flushleft]{threeparttable}
\usepackage{rotating}
\usepackage{kotex}   % for Korean

% new commands
%\DeclarePairedDelimiter\abs{\lvert}{\rvert}
%\DeclarePairedDelimiter\norm{\lVert}{\rVert}
\long\def\comment#1{}

%\newtheorem*{thm}{Theorem}
\newtheorem{thm}{Theorem}[section]
\newtheorem{cor}[thm]{Corollary}
\newtheorem{lem}[thm]{Lemma}
\newcommand{\rb}[1]{\raisebox{-.5em}[0pt]{#1}}
% \renewcommand{\baselinestretch}{1.8}
\renewcommand{\mid}{\, | \ }
\newcommand{\eighth}{{\textstyle \frac{1}{8}}}

\def \bY { \mathbf{ Y } }
\def \bX { \mathbf{ X } }
\def \bU { \mathbf{ U } }
\def \bmu { \boldsymbol{ \mu } }
\def \bSigma { \boldsymbol{ \Sigma } }
\def \bphi { \boldsymbol{ \phi } }
\def \bepsilon { \boldsymbol{ \epsilon } }
\def \bD { \boldsymbol{\mathcal{D}} }

\newcommand{\eqdis}{\overset{\mathrm{d}}{=\joinrel=}}
\newcommand{\ba}{\mbox{\boldmath $a$}}
\newcommand{\bg}{\mbox{\boldmath $g$}}
\newcommand{\bx}{\mbox{\boldmath $x$}}
\newcommand{\by}{\mbox{\boldmath $y$}}
\newcommand{\bd}{\mbox{\boldmath $d$}}
\newcommand{\bff}{\mbox{\boldmath $f$}}
\newcommand{\bz}{\mbox{\boldmath $z$}}
\newcommand{\bu}{\mbox{\boldmath $u$}}
\newcommand{\bv}{\mbox{\boldmath $v$}}
\newcommand{\bW}{\mbox{\boldmath $W$}}
\newcommand{\bI}{\mbox{\boldmath $I$}}
\newcommand{\bJ}{\mbox{\boldmath $J$}}
\newcommand{\bL}{\mbox{\boldmath $L$}}
\newcommand{\bQ}{\mbox{\boldmath $Q$}}
\newcommand{\bZ}{\mbox{\boldmath $Z$}}
\newcommand{\bV}{\mbox{\boldmath $V$}}
\newcommand{\bG}{\mbox{\boldmath $G$}}
\newcommand{\bdm}{\begin{displaymath}}
\newcommand{\edm}{\end{displaymath}}
\newcommand{\bnu}{\mbox{\boldmath $\nu$}}
\newcommand{\btau}{\mbox{\boldmath $\tau$}}
\newcommand{\biota}{\mbox{\boldmath $\iota$}}
\newcommand{\bbeta}{\mbox{\boldmath $\beta$}}
\newcommand{\bomega}{\mbox{\boldmath $\omega$}}
\newcommand{\btheta}{\mbox{\boldmath $\theta$}}
\newcommand{\bep}{\mbox{\boldmath $\epsilon$}}
\newcommand{\bdelta}{\mbox{\boldmath $\delta$}}
\newcommand{\balpha}{\mbox{\boldmath $\alpha$}}
\newcommand{\bxi}{\mbox{\boldmath $\xi$}}
\newcommand{\bgamma}{\mbox{\boldmath $\gamma$}}
\newcommand{\bOmega}{\mbox{\boldmath $\Omega$}}
\newcommand{\bPi}{\mbox{\boldmath $\Pi$}}
\newcommand{\bzeta}{\mbox{\boldmath $\zeta$}}
\newcommand{\bpsi}{\mbox{\boldmath $\psi$}}
\newcommand{\bPsi}{\mbox{\boldmath $\Psi$}}
\newcommand{\bl}{\mbox{\boldmath $l$}}
\newcommand{\C}{{\rm Cov}}
\newcommand{\bH}{\bold H}
\newcommand{\blambda}{\mbox{\boldmath $\lambda$}}
\newcommand{\bbh}{\bld h}
\newcommand{\calA}{\mathcal{A}}
\newcommand{\calB}{\mathcal{B}}
\newcommand{\calE}{\mathcal{E}}
\newcommand{\calX}{\mathcal{X}}
\newcommand{\calY}{\mathcal{Y}}
\newcommand{\bbR}{\mathbb{R}}
\newcommand{\union}{\bigcup}
\newcommand{\intersect}{\bigcap}
\newcommand{\eqdef}{\overset{\mathrm{def}}{=}}


%
% Basic Document Settings
%

\topmargin=-0.45in
\evensidemargin=0in
\oddsidemargin=0in
\textwidth=6.5in
\textheight=9.0in
\headsep=0.25in

\linespread{1.2}

\pagestyle{fancy}
\lhead{\leftmark}
%\chead{\hmwkClass\ (\hmwkClassInstructor\ \hmwkClassTime): \hmwkTitle}
\rhead{\authorName}
%\lfoot{\lastxmark}
\cfoot{\thepage}

\renewcommand\headrulewidth{0.4pt}
\renewcommand\footrulewidth{0.4pt}

\setlength\parindent{0pt}

%%
%% Create Problem Sections
%%
%
%\newcommand{\enterProblemHeader}[1]{
%    \nobreak\extramarks{}{Problem \arabic{#1} continued on next page\ldots}\nobreak{}
%    \nobreak\extramarks{Problem \arabic{#1} (continued)}{Problem \arabic{#1} continued on next page\ldots}\nobreak{}
%}
%
%\newcommand{\exitProblemHeader}[1]{
%    \nobreak\extramarks{Problem \arabic{#1} (continued)}{Problem \arabic{#1} continued on next page\ldots}\nobreak{}
%    \stepcounter{#1}
%    \nobreak\extramarks{Problem \arabic{#1}}{}\nobreak{}
%}
%
%\setcounter{secnumdepth}{0}
%\newcounter{partCounter}
%\newcounter{homeworkProblemCounter}
%\setcounter{homeworkProblemCounter}{1}
%\nobreak\extramarks{Problem \arabic{homeworkProblemCounter}}{}\nobreak{}
%
%%
%% Homework Problem Environment
%%
%% This environment takes an optional argument. When given, it will adjust the
%% problem counter. This is useful for when the problems given for your
%% assignment aren't sequential. See the last 3 problems of this template for an
%% example.
%%
%\newenvironment{homeworkProblem}[1][-1]{
%    \ifnum#1>0
%        \setcounter{homeworkProblemCounter}{#1}
%    \fi
%    \section{Problem \arabic{homeworkProblemCounter}}
%    \setcounter{partCounter}{1}
%    \enterProblemHeader{homeworkProblemCounter}
%}{
%    \exitProblemHeader{homeworkProblemCounter}
%}

%
% Homework Details
%   - Title
%   - Due date
%   - Class
%   - Section/Time
%   - Instructor
%   - Author
%

%\newcommand{\hmwkTitle}{}
%\newcommand{\hmwkClass}{Theoretical Statistics: Topics for a Core Course\\ Solution}
%\newcommand{\hmwkClassTime}{}
%\newcommand{\hmwkClassInstructor}{Robert W. Keener}

\newcommand{\courseTitle}{Theoretical Statistics: Topics for a Core Course \\ Summary Note}
\newcommand{\bookAuthor}{Robert W. Keener}
\newcommand{\authorName}{Hyunsung Kim}



%
% Title Page
%

\title{
    \vspace{1.5in}
%    \textmd{\textbf{\hmwkClass:\ \hmwkTitle}}\\
    \textmd{\textbf{\courseTitle}}\\
%    \normalsize\vspace{0.1in}\hmwkDueDate\\
    \vspace{0.1in}\large{\textit{\bookAuthor}}
    \vspace{2in}
}
\date{Update: \today}
\author{
    {\sc \authorName} \\
    Department of Statistics\\
    Chung-Ang University
}



\renewcommand{\part}[1]{\textbf{\large Part \Alph{partCounter}}\stepcounter{partCounter}\\}

%
% Various Helper Commands
%

% Useful for algorithms
\newcommand{\alg}[1]{\textsc{\bfseries \footnotesize #1}}

% For derivatives
\newcommand{\deriv}[1]{\frac{\mathrm{d}}{\mathrm{d}x} (#1)}

% For partial derivatives
\newcommand{\pderiv}[2]{\frac{\partial}{\partial #1} (#2)}

% Integral dx
\newcommand{\dx}{\mathrm{d}x}
\newcommand{\dmu}{\mathrm{d}\mu}
\newcommand{\dP}{\mathrm{d}P}

% Alias for the Solution section header
\newcommand{\solution}{\textbf{\large Solution}}

% Probability commands: Expectation, Variance, Covariance, Bias
\newcommand{\E}{\mathrm{E}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\Cor}{\mathrm{Cor}}
\newcommand{\Bias}{\mathrm{Bias}}

% Specify level of toc(table of content)
\setcounter{tocdepth}{1}

% Setting for blank page appeared when begin new chapter
\let\cleardoublepage=\clearpage



\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}[theorem]{Definition}

\theoremstyle{definition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{example}[theorem]{Example}
%\newtheorem{definition}{Definition}[section]


%%% Main part
\begin{document}

% Title page
\maketitle

% Table of Contents
\tableofcontents

% Preface
\input{Chapter/preface.tex}

% Test file
%\input{Chapter/math_test.tex}

% Chapter 1. Probability and Measure
\input{Chapter/chapter1.tex}
\chapter{Probability and Measure}

%% 1.1
\section{Measures}

\begin{definition}[$\sigma$-algebra]
A collection of $\calA$ of subsets of a set $\calX$ is a $\sigma$-algebra (or $\sigma$-field) if
\begin{enumerate}
    \item $\calX \in \calA$ and $\emptyset \in \calA$,
    \item If $A \in \calA$, then $A^c = \calX - A \in \calA$,
    \item If $A_1, A_2, \dots \in \calA$, then $\union_{i=1}^\infty A_i \in \calA$.
\end{enumerate}
\end{definition}

\begin{definition}[Measure]
A function $\mu$ on a $\sigma$-algebra $\calA$ of $\calX$ is a measure if
\begin{enumerate}
	\item For every $A \in \calA, ~ 0 \le \mu(A) \le \infty$; that is, $\mu: \calA \rightarrow [0, \infty]$.
	\item (Countable Additivity) If $A_1, A_2, \dots$ are disjoint elements of $\calA$, then
	$$ \mu\left( \union_{i=1}^\infty A_i \right) = \sum_{i=1}^\infty \mu(A_i).$$
\end{enumerate}
\end{definition}

\begin{example}
For a measure $\mu$ on a set $\calX$ and subsets $A \in \calX$, 
\begin{enumerate}
	\item $\mu$ is {\em counting measure} on $\calX$ if $\calX$ is countable, and define
	$$ \mu(A) = \# A = \text{number of points in }A,$$
	and also its $\sigma$-algebra $\calA$ be the {\em power set} of $\calX$, denoted $\calA = 2^\calX$.

	\item $\mu$ is {\em Lebesgue measure} on $\calX$ if $\calX = \bbR^n$, and define
	$$\mu(A) = \underset{A}{\int \cdots \int} \dx_1\cdots dx_n,$$
	and for any set $A$ in a $\sigma$-algebra $\calA$ called the {\em Borel sets} of $\calX = \bbR^n$, and formally $\calA$ is the smallest $\sigma$-algebra that contains all open set in $\bbR^n$ ("rectangles").
	
	\item $\mu$ is {\em probability measure} on $\calX$ if $\mu(\calX) = 1$.
\end{enumerate}
\end{example}




\begin{remark}
If $\calA$ is a $\sigma$-algebra of subsets of $\calX$, the pair $(\calX, \calA)$ is called a {\em measurable space}, and if $\mu$ is a measure on $\calA$, the triple $(\calX, \calA, \mu)$ is called a {\em measure space}.
\end{remark}

\begin{proposition}[Continuity property of measures]
If measurable sets $B_n, ~ n \ge 1$, are increasing ($B_1 \subset B_2 \subset \cdots$), with $B = \union_{i=1}^\infty B_n$, called the limit of the sequence, then
	$$ \mu(B) = \lim_{n\rightarrow \infty} \mu(B_n). $$
If a measure $\mu$ is a probability measure, it also holds for decreasing sets ($B_1 \supset B_2 \supset \cdots$) and its limit $B = \intersect_{n=1}^\infty B_n$.
\begin{proof}
생략
\end{proof}
\end{proposition}


\begin{definition}[$\sigma$-finite] There is some notations and definitions about the measure.
\begin{enumerate}	
	\item A measure $\mu$ is finite if $\mu(\calX) < \infty$.
	\item A measure $\mu$ is $\sigma$-finite if $\exists A_1,A_2,\dots \in \calA$ with $\mu(A_i) < \infty ~ \forall i = 1, 2, \dots$ and $\union_{i=1}^\infty A_i = \calX$.
\end{enumerate}
\end{definition}

\begin{remark}
A probability measure is $\sigma$-finite.
\end{remark}


%% 1.2
\section{Integration}

\begin{example} The integral of "nice" function $f$ against a measure $\mu$ is written as $\int f d\mu$ or $\int f(x) d\mu(x)$.
    \begin{enumerate}
        \item If $\mu$ is {\em counting measure} on $\calX$, then the integral of $f$ against $\mu$ is
        $$ \int f d\mu = \sum_{x \in \calX} f(x). $$
        \item If $\mu$ is {\em Lebesgue measure} on $\bbR^n$, then the integral of $f$ against $\mu$ is
        $$ \int f d\mu = \int \cdots \int f(x_1, \dots, x_n) dx_1 \dots dx_n. $$
    \end{enumerate}
\end{example}

\begin{definition}[Measurable]
    If $(\calX, \calA)$ is a measurable space and $f$ is a real-valued function on $\calX$, then $f$ is measureble if
    $$ f^{-1}(B) \eqdef \{ x \in \calX : f(x) \in B \} \in \calA, $$
    for every Borel set $B$.
\end{definition}

\begin{definition}[Indicator function]
    The indicator function $1_A$ of a set $A$ is defined as
    $$ 
    1_A(x) = I\{x \in A\} = \begin{cases} 
                            1, & x \in A, \\
                            0, & x \not\in A.
                            \end{cases}
    $$
\end{definition}

\begin{proposition}\label{prop:indicator}
    The integral of the indicator function $1_A$ has following properties:
    \begin{enumerate}
        \item For any set $A \in \calA$, $\int 1_A d\mu = \mu(A)$.
        \item If $f$ and $g$ are non-negative measurable functions, and if $a$ and $b$ are positive constants,
        $$ \int (af + bg) d\mu = a\int f d\mu + b\int g d\mu. $$
        \item If $f_1 \le f_2 \le \cdots$ are non-negative measurable functions, and if $f(x) = \lim_{n \rightarrow \infty} f_n(x)$, then 
        $$ \int f d\mu = \lim_{n \rightarrow \infty} \int f_n d\mu. $$
    \end{enumerate}
    \begin{proof}
    생략
    \end{proof}
\end{proposition}

\begin{definition}[Simple function]
A function $f$ is simple if
$$ f = \sum_{i=1}^m a_i 1_{A_i}, $$
where $a_a, \dots, a_m$ are positive constants, and $A_1, \dots, A_m$ are sets in $\calA$
\end{definition}

\begin{remark}
By using 1 and 2 in Proposition \ref{prop:indicator}, the integral of simple function is obtained as
$$ \int \left( \sum_{i=1}^m a_i 1_{A_i} \right) d\mu = \sum_{i=1}^m a_i \mu(A_i). $$
\end{remark}

\begin{theorem}
If $f$ is non-negative and measurable, then there exist non-negative simple functions $f_1 \le f_2 \le \cdots$ with $f = \lim_{n \rightarrow \infty} f_n$.
\begin{proof}
생략
\end{proof}
\end{theorem}

\begin{definition}[Integrable]
% For non-negative measurable function $f$, and define $f^+(x) = \max\{f(x), 0\} and f^-(x) = -\min\{f(x), 0\}$.
% \begin{enumerate}
%     \item $f = f^+ - f^-$.
%     \item $|f| = f^+ + f^-$.
%     \item A function $f$ is integrable if $\int |f| d\mu < \infty$.
% \end{enumerate}
A measurable function $f$ is integrable if $\int |f| d\mu < \infty$.
\end{definition}


%% 1.3
\section{Events, Probabilities, and Random Variables}
\begin{definition}[Probability space]
If $\calE$ is a sample space,  $\calB$ is a $\sigma$-algebra of subsets of $\calX$, and $P$ is a probability measure, then the triple $(\calX, \calA, P)$ is called a  probability space.
Also $B \in \calB$ are called events, points $e \in \calE$ are called outcomes, and $P(B)$ is called the probability of B.
\end{definition}

\begin{definition}[Random variable]
A measurable function $X: \calE \rightarrow \bbR$ is called a random variable.
\end{definition}

\begin{definition}[Distribution]
The probability measure $P_X$ is defined by
$$ P_X(A) = P\left(\{ e \in \calE : X(e) \in A \}\right) \overset{\mathrm{def}}{=} P(X \in A), $$ 
for Borel sets $A$ is called distribution of $X$, and if we let $P_X := Q$, then it is denoted as $X \sim Q$, means that a random variable $X$ has distribution $Q$.
\end{definition}

\begin{definition}[Cumulative distribution function]
The cumulative distribution function of $X$ is defined by 
$$ F_X(x) = P(X \le x) = P\left(\{ e \in \calE : X(e) \le x \}\right) = P_X\left((-\infty, x]\right),$$
for $x \in \bbR.$
\end{definition}


%% 1.4
\section{Null Sets}

\begin{definition}[Null set]
For a measure $\mu$ on the measuruable space $(\calX, \calA)$, a set $N$ is called null with respect to $\mu$ if 
$$ \mu(N) = 0. $$
\end{definition}

\begin{definition}[Almost everywhere]
If a statement holds for $x \in \calX-N$ with $N$ null, the statement is said to hold almost everywhere (a.e.) or a.e. $\mu$.
\end{definition}

\begin{example}
    $f = 0$ a.e. $\mu$ $\Longleftrightarrow \mu\left( \{ x\in \calX : f(x) \ne 0 \} \right) = 0.$ 
\end{example}

\begin{remark}[Almost sure]
For the probability space, the statement holds a.e. if and only if $\mu(B^c) = 0$ or $\mu(B) = 1$.
Especially, it can be denoted that the statement holds {\em almost surely (a.s.)} or {\em with probability one}. 
\end{remark}

\begin{proposition}
    There are a few useful facts about integration:
    \begin{enumerate}
        \item If $f = 0 ~ (a.e. ~ \mu$), then $\int f d\mu = 0$.
        \item If $f \ge 0$ and $\int f d\mu=0$, then $f = 0 ~ (a.e. ~ \mu$).
        \item If $f = g ~ (a.e. ~ \mu)$, then $\int f d\mu = \int g d\mu$ for at least of the integral exists.
        \item If $\int 1_{(c,x)}f d\mu = 0$ for all $x > c$, then $f(x) = 0$ for $a.e. ~ x > c$. The constant $c$ here can be $-\infty$.
        \item If f and g are integrable and $f > g$, then $\int f d\mu > \int g d\mu$. \rm{(From 2)}
    \end{enumerate}
    \begin{proof}
    생략
    \end{proof}
\end{proposition}


%% 1.5
\section{Densities}

\begin{definition}[Absolutely continuity]
Let P and $\mu$ be measures on a $\sigma$-field $\calA$ of $\calX$. Then P is called absolutely continuous with respect to $\mu$, written $P \ll \mu$, if $P(A) = 0$ whenever $\mu(A) = 0$.
\end{definition}

\begin{theorem}[Radon-Nikodym]\label{thm:radon}
If a finite measure P is absolutely continuous with respect to a $\sigma$-finite measure $\mu$, then there exists a non-negative measurable function f such that 
$$ P(A) = \int_A f d\mu \eqdef \int f 1_A d\mu. $$
\end{theorem}

\begin{remark}
The function $f$ in Theorem \ref{thm:radon} is called Radon-Nikodym derivitive of $P$ with respect to $\mu$, or the {\em density} of $P$ with respect to $\mu$, denoted 
$$ f = \frac{dP}{d\mu}. $$
\end{remark}

\begin{remark}
If $X \sim P_X$ and $P_X$ is absolutely continuous with respect to $\mu$ with density $p = dP_X / d\mu$, it is called that {\em X has density p with repect to $\mu$}.
\end{remark}

\begin{example}[Absolutely continuous random variables]
    If a random variable X has density p with respect to Lebesgue measure on $\bbR$, then X or its distribution $P_X$ is called {\em absolutely continuous} with density p. Then, from the Radon-Nikodym theorem,
    $$ F_X(x) = P(X \le x) = P_X\left( (-\infty, x] \right) = \int_{-\infty}^x p(u)du $$
    And also by fundamental theorem of calculus, $p(x) = F_X'(x)$.
\end{example}

\begin{example}[Discrete random variables]
    Let $\calX_0$ be a countable subset of $\bbR$. The measure $\mu$ defined by
    $$ \mu(B) = \# (\calX_0 \cap B) $$
    for Borel sets $B$ is (also) called {\em counting measure on $\calX_0$}. Then, the integration is defined as
    $$ \int f d\mu = \sum_{x \in \calX_0} f(x). $$
    If a random variable $X$ satisfies
    $$ P(X \in \calX_0) = P_X(\calX_0) = 1, $$
    then $X$ is called a {\em discrete random variable}.
    And also $P_X$ is absolutely continuous with respect to $\mu$. (See the textbook page 8.)
        
    The density $p$ of $P_X$ with respect to $\mu$ satisfies
    $$ P(X \in A) = P_X(A) = \int_A p d\mu = \sum_{x \in \calX_0} p(x) 1_A(x). $$
    If $A = \{y\}$ with $y \in \calX_0$, then
    $$P(X = y) = \sum_{x \in \calX_0}p(x)1_{\{y\}}(x) = p(y).  $$
    This density $p$ is called the {\em mass function} for $X$.
\end{example}



%% 1.6 Expectation
\section{Expectation}

\begin{definition}[Expectation]
If $X$ is a random variable on a probability space $(\calE, \calB, P)$, then the expectation or expected value of $X$ is defined as 
$$EX = \int X dP.$$
If $X \sim P_X$, then
$$ EX = \int x dP_X(x). $$
Also, if $Y= f(X)$, then
$$ EY = Ef(X) = \int f dP_X. $$
\end{definition}

\begin{remark}
	If $P_X$ has density $p$ with respect to $\mu$, then
	$$ \int f dP_X = \int fp d\mu. $$
\end{remark}

\begin{example}
If $X$ is an absolutely continuous random variable with density $p$, then
$$ EX = \int xdP_X(x) = \int xp(x)dx $$
and
$$ Ef(X) = \int f(x)p(x)dx. $$
\end{example}

\begin{example}
If $X$ is a discrete with $P(X \in \calX_0) = 1$ for a countable set $\calX_0$, if $\mu$ is counting measure on $\calX_0$, and if $p$ is the mass function given by $p(x) = P(X=x)$, then
$$ EX = \int xdP_X(x) = \int xp(x)d\mu(x) = \sum_{x \in \calX_0} xp(x) $$
and 
$$ Ef(X) = \sum_{x\in \calX_0} f(x)p(x). $$
\end{example}

\begin{proposition}
If $X$ and $Y$ are random variables with finite expectations, the followings are satisfied.
\begin{enumerate}
	\item For $a$ and $b$ are nonzero constants, 
		$$E(aX+bY) = aEX + bEY.$$
	\item If $X \le y$ (a.e. $P$), then $EX \le EY$, and equality holds if $X=Y$ (a.e. $P$).
\end{enumerate}
\begin{proof}
 생략
\end{proof}
\end{proposition}

\begin{definition}[Variance]
The variance of a random variable $X$ with finite expectation is defined as
$$ \Var(X) = E(X-EX)^2 = EX^2 - (EX)^2. $$
\begin{enumerate}
	\item If $X$ is absolutely continuous with density $p$,
		$$ \Var(X) = \int (x-EX)^2p(x)dx. $$
	\item If $X$ is discrete with mass function $p$,
		$$ \Var(X) = \sum_{x \in \calX_0} (x-EX)^2p(x). $$
\end{enumerate}
\end{definition}

\begin{definition}[Covariance]
The covariance between two random variables $X$ and $Y$ with finite expectation is defined as
$$ \Cov(X,Y) = E(X-EX)(Y-EY) = EXY - (EX)(EY). $$
\end{definition}

\begin{definition}[Correlation]
The correlation between two random variables $X$ and $Y$ with finite expectation is defined as
$$ \Cor(X,Y) = \frac{\Cov(X,Y)}{\sqrt{\Var(X)\Var(Y)}}, $$
and it always lie in $[-1, 1]$.
\end{definition}


%% 1.7 Random Vectors
\section{Random Vectors}

\begin{definition}[Random vector]
If $X_1, \dots, X_n$ are random variables, then the function $X: \calE \to \bbR^n$ defined by
$$ X(e) =  \begin{pmatrix}
X_1(e) \\
\vdots \\
X_n(e)
\end{pmatrix}, ~~~~~ e \in \calE, $$
is called a random vector.
\end{definition}

\begin{remark} 
Similarly with the random variables, the notations of random vectors is directly extended by follows:
\begin{enumerate}
	\item The distribution of $P_X$ of $X$ is defined by
		$$ P_X(B) = P(X\in B) \eqdef P\big( \{e\in\calE : X(e) \in B \big) $$
		for Borel sets $B \in \bbR^n$, and denote $X \sim P_X$.
	\item The random vector $X$ or its distribution $P_X$ is called {\em absolutely continuous} with density $p$ if $P_X$ is absolutely continuous with respect to Lebesgue measure on $\bbR^n$. And the probability is defined as
		$$ P(X \in B) = \underset{B}{\int\cdots\int} p(x)dx. $$
		
	\item The random vector $X$ is {\em discrete} if $P(X \in \calX_0) = 1$ for some countable set $\calX_0 \subset \bbR^n$.
		If $p(x) = P(X= x)$, then $P_X$ has density $p$ with respect to counting measure on $\calX_0$ and
		$$ P(X \in B) = \sum_{x \in \calX \cap B} p(x). $$
	\item The expectation of random vector $X$ is defined as
		$$ EX = \begin{pmatrix}
		EX_1 \\
		\vdots \\
		EX_n
		\end{pmatrix}. $$
		If $T: \bbR^n \to \bbR$ is a measurable function, then $T(X)$ is a random variable, and with finite integral,
		$$ ET(X) = \int T dP_X. $$
		If $P_X$ has a density $p$ with respect to a dominating measure $\mu$, this integral can be expressed as $\int T pd\mu$, which becomes
		$$ \sum_{x \in \calX_0} T(x)p(x) \text{ or } \int \cdots \int T(x)p(x)dx, $$
		where discrete and absolutely continuous cases with $\mu$ counting or Lebesgue measure, respectively.
\end{enumerate}
\end{remark}



%% 1.8 Covariance Matrices
\section{Covariance Matrices}

\begin{definition}[Random matrix]
	A matrix $W$ is called a random matrix if the entires $W_{ij}$ are random variables.
\end{definition}

\begin{definition}[Expectation of random matrix]
	If $W$ is a random matrix, then $EW$ is the matrix of expectations of the entries,
	$$ (EW)_{ij} = EW_{ij}. $$
\end{definition}

\begin{definition}[Covariance matrix]
	The covariance of a random vector $X$ is the matrix of covariances of the variables in $X$; that is,
	$$ \big[ \Cov(X) \big]_{ij} = \Cov(X_i,X_j). $$
	If $\mu = EX$ and $(X-\mu)'$ denotes the transpose of $X-\mu$, a (random) row vector, then
	$$ \Cov(X_i,X_j) = E(X_i-\mu_i)(X_j - \mu_j) = E\big[ (X-\mu)(X-\mu)'  \big]_{ij}, $$
	and so
	$$ \Cov(X) = E(X-\mu)(X-\mu)' = EXX' - \mu\mu'. $$
\end{definition}

\begin{remark}
	If $v$ is a constant vector, $A$, $B$, and $C$ are constant matrices, $X$ is a random vector, and $W$ is a random matrix, then
	\begin{enumerate}
		\item $ E[v + AX] = v + AE(X).$
		\item $ E[A+BWC] = A+B(EW)C. $
		\item $ \Cov(v + AX) = A\Cov(X)A'. $
	\end{enumerate}
	\begin{proof}
		By using the definitions and the simple matrix algebra, these are trivial.
	\end{proof}
\end{remark}



%% 1.9 Product Measures and Independence
\section{Product Measures and Independence}

\begin{definition}[Product measure]
Let $(\calX, \calA, \mu)$ and $(\calY, \calB, \nu)$ are measure spaces.
Then there exists a unique measure $\mu \times \nu$, called the product measure, on $(\calX \times \calY, \calA \lor \calB)$ such that 
$$ (\mu \times \nu)(A \times B) = \mu(A) \nu(B), $$
for all $A \in \calA$ and all $B \in \calB$.
The $\sigma$-algebra $\calA \lor \calB$ is defined formally as the smallest $\sigma$-algebra containing all sets $A \times B$ with $A \in \calA$ and $B \in \calB$.
\end{definition}


\begin{example}
	These are simple examples of product measure.
        \begin{enumerate}
                \item If $\mu$ and $\nu$ are Lebesgue measures on $\bbR^n$ and $\bbR^m$, respectively, then $\mu \times \nu$ is Lebesgue measure on $\bbR^{n+m}$.
                \item If $\mu$ and $\nu$ are counting measures on sets $\calX_0$ and $\calY_0$, then $\mu \times \nu$ is counting measure on $\calX_0 \times \calY_0$.
        \end{enumerate}
\end{example}


\begin{theorem}[Fubini]
If $f \ge 0$ or $f$ is integrable which means $\int |f| d(\mu \times \nu) < \infty$, then
\begin{align*}
	\int f d(\mu \times \nu) &= \int \left[ \int f(x,y)d\nu(y)\right] d\mu(x) \\
					  &= \int \left[ \int f(x,y) d\mu(x) \right] d\nu(y).
\end{align*}
\begin{proof}
See Royden p.418(Statement) and p.421(Proof), or Durrett p.34 Theorem 1.7.2.
\end{proof}
\end{theorem}


\begin{definition}[Independence]
Two random vectors, $X \in \bbR^n$ and $Y \in \bbR^m$ are independent if 
$$ P(X \in A, Y \in B) = P(X \in A)P(Y \in B), $$
for all Borel sets $A$ and $B$.

\end{definition}




















\end{document}